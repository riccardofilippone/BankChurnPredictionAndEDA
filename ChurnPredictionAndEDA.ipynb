{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPXltUjVBmNq0DD+8fAKV2J"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Churn Prediction And Exploratory Data Analisys"
      ],
      "metadata": {
        "id": "9q5ia1HH3MZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hois0HPR3ymZ"
      },
      "outputs": [],
      "source": [
        "# Load Kaggle file\n",
        "\n",
        "! pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset from kaggle\n",
        "\n",
        "! kaggle datasets download 'radheshyamkollipara/bank-customer-churn'\n",
        "\n",
        "! mkdir Data\n",
        "\n",
        "! unzip bank-customer-churn.zip -d Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"./Data/Customer-Churn-Records.csv\")\n",
        "\n",
        "# Check if the dataset has missing values\n",
        "missing_percentage = df.isna().sum() / len(df) * 100\n",
        "missing_percentage = missing_percentage[missing_percentage != 0]\n",
        "print(df.isna().sum(), missing_percentage)\n",
        "\n",
        "# Remove unnecessary columns\n",
        "df.drop([\"Surname\", \"CustomerId\", \"RowNumber\"], inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "F5jXdzzGy3ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check how many have left\n",
        "print(df[\"Exited\"].value_counts())"
      ],
      "metadata": {
        "id": "Bm_CC_gT0zGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the dataset column into numerical and categorical\n",
        "numerical = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'Satisfaction Score', 'Point Earned']\n",
        "categorical = ['Geography', 'Gender', 'Card Type', 'IsActiveMember', 'Complain']"
      ],
      "metadata": {
        "id": "cJYXO4UO0xO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Matplotlib and seaborn graphs style\n",
        "\n",
        "sns.set(style=\"darkgrid\", context=\"paper\")\n",
        "plt.style.use(\"dark_background\")\n",
        "plt.rcParams.update({\"grid.linewidth\": 0.5, \"grid.alpha\": 0.5})\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "UnzY_TmqzAh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart to check how many have left\n",
        "\n",
        "pal = sns.color_palette(\"rocket\", n_colors=2) # Color palette\n",
        "sns.set_context(\"paper\")\n",
        "ax = sns.countplot(\n",
        "    data=df,\n",
        "    x='Exited',\n",
        "    palette=pal,\n",
        ")\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container) # Add number on top of bars"
      ],
      "metadata": {
        "id": "fGxiYioR06gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for all the numerical fields\n",
        "\n",
        "pal = iter(sns.color_palette(\"rocket\", n_colors=len(numerical)))\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "for i, col in enumerate(numerical):\n",
        "    plt.subplot(2, int(len(numerical) / 2), i + 1)\n",
        "    sns.histplot(\n",
        "        x=str(col),\n",
        "        data=df,\n",
        "        color=next(pal),\n",
        "        bins=20\n",
        "    )\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "gsAZRFGrzRiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart for the categorical ones\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "for i, col in enumerate(categorical):\n",
        "    pal = sns.color_palette(\"rocket\", n_colors=len(df[col].unique()))\n",
        "    ax = plt.subplot(2, int(len(categorical) / 2) + 1, i + 1)\n",
        "    sns.countplot(\n",
        "        x=str(col),\n",
        "        data=df,\n",
        "        palette=pal,\n",
        "    )\n",
        "    for container in ax.containers:\n",
        "        ax.bar_label(container, )\n",
        "    plt.legend([], [], frameon=False)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "Og6Wbmz7zVIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "correlation_matrix = df.corr(numeric_only=True)\n",
        "sns.heatmap(correlation_matrix, xticklabels=correlation_matrix.columns, yticklabels=correlation_matrix.columns, annot=True)"
      ],
      "metadata": {
        "id": "2NVXHPXrzm3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Violin graphs to check the relationship between Complain and Age given the high correlation\n",
        "\n",
        "g = sns.FacetGrid(df, col='Gender', height=4, aspect=0.8)\n",
        "\n",
        "pal = sns.color_palette(\"rocket\", n_colors=2)\n",
        "g.map_dataframe(sns.violinplot, x='Complain', y ='Age', palette=pal)"
      ],
      "metadata": {
        "id": "OoS7mSBazo_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And boxplots for the categorical fields in relation to age\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, col in enumerate(categorical):\n",
        "    pal = sns.color_palette(\"rocket\", n_colors=len(df[col].unique()))\n",
        "    plt.subplot(2, int(len(categorical) / 2) + 1, i + 1)\n",
        "    sns.boxplot(\n",
        "        x=str(col),\n",
        "        y='Age',\n",
        "        data=df,\n",
        "        palette=pal\n",
        "    )\n",
        "    plt.legend([], [], frameon=False)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "loSP0YWtzqpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "models = [\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Decision Tree', DecisionTreeClassifier()),\n",
        "    ('SVM', SVC()),\n",
        "    ('Logistic Regression', LogisticRegression())\n",
        "]"
      ],
      "metadata": {
        "id": "vKedBMbO62Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_score_model(model, model_name, X_train, y_train, X_test, y_test):\n",
        "    model.fit(X_train, y_train.ravel()) # Fit the model\n",
        "    predictions = model.predict(X_test) # Predict the values\n",
        "    test_rmse = mean_squared_error(y_test, predictions, squared=False) # Calculate the Root Mean Square Error\n",
        "\n",
        "    score = model.score(X_test, y_test.ravel()) # Calculate the score\n",
        "\n",
        "    print(f\"Model Name: {model_name}, RMSE: {test_rmse}, Score: {score}\")"
      ],
      "metadata": {
        "id": "YFntqb4s6uVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_to_label = df[['Geography', 'Gender', 'Card Type']] # The columns to One Hot Encode"
      ],
      "metadata": {
        "id": "d0wgLOGh6xc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(features_to_label, columns=features_to_label.columns.values)"
      ],
      "metadata": {
        "id": "AZzQepnnUr60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "df_cat = features_to_label.apply(le.fit_transform)"
      ],
      "metadata": {
        "id": "k3CowxiX69ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = df.drop(['Geography', 'Gender', 'Card Type'], axis=1)\n",
        "df = pd.merge(numerical_features, df_encoded, left_index=True, right_index=True)"
      ],
      "metadata": {
        "id": "n9Cd6fCb7BVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['Exited'], axis=1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X) # Scale the dataset\n",
        "\n",
        "y = df['Exited']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3)\n",
        "\n",
        "for model_name, model in models:\n",
        "  fit_score_model(model, model_name, X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "id": "TrMlK-HL7E0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}